* **アーキテクチャの方向性は◎**（AI-ネイティブ：Doc/Chunk/Vector＋Entity/Event、MCP公開、pgvector）。
* **初日コードは “雛形としては合格、実行体としては未完成（要修正多数）”。**
  ファイル内に **プレースホルダ（`...`）や途中で切れた行** が多く、このままでは起動しません。
* **最短で動かすには**：RSS取り込み→埋め込み→MCPサーバの「`doc_head` と `semantic_search`」の2系統だけを**先に確実に**直しましょう（下にパッチ案あり）。

---

# 総評（良い点）

* **データモデルが理想的**：`doc / chunk / chunk_vec / entity / event / hint` の分離はAI検索に最適。
* **MCPのI/Fが最小JSONで設計**されており、LLMから扱いやすい（`title/published_at/genre_hint/url`）。
* **運用の雛形が揃っている**：`systemd` の `ingest.timer / embed.timer`、評価SQL、再開マニュアル。
* **セキュリティの素地**：`EnvironmentFile` を使うユニット有（NewsAPI）。

---

# 走らせた所感（Zip内容を確認）

* 構成：37ファイル。主要ディレクトリ：`db/`（スキーマ v2）、`scripts/`（ingest/embed/eval）、`mcp_news/`（MCPサーバ）、`deploy/`（systemd）、`docs/`（レポート/手順）。
* **ドキュメント**：`FINAL_REPORT.md` と `RESUME_MANUAL.md` は良質。`README_UBUNTU.md` に軽微な体裁崩れあり（重複コードフェンス）。

---

# ブロッキング（起動不能）— 優先度：最上

以下は**必ず修正が必要**です。

1. **ファイル内の `...`（省略記号）が実コードの代わりに残っている**

   * `scripts/ingest_rss.py / ingest_newsapi.py / ingest_hn.py / embed_chunks.py / mcp_news/server.py` など複数。
     → すべて**実コードに置換**が必要（生成途中のままコミットされた状態）。

2. **`ingest_rss.py` の `to_utc` が途中で切れている**

   * 末尾が `return dat` で未定義変数（コンパイルエラー）。

3. **`mcp_news/server.py` が部分的に破損**

   * SQL文字列に `eve...t` や `e...._geohash` が混入。
   * `semantic_search` で **`embedding_space` フィルタ欠落**（誤った空間が混ざる）。
   * 起動関数が `mcp.run()` になっており、**Transport未指定**（`run_stdio()` を推奨）。

4. **`ingest_newsapi.py / ingest_hn.py` の main / argparse 定義が断片**

   * `mai` で切れている／`--kind` のchoices行が途中など。

---

# 重大（品質・性能に効く）— 優先度：高

* **pgvectorのインデックス**がコメントアウトのまま

  * HNSW（`USING hnsw`）を**embedding\_spaceごと**に作るべき。
* **`semantic_search` の距離演算と索引の整合**

  * `sentence-transformers` で **正規化埋め込み(cos類似)** を使うなら
    **`vector_cosine_ops`** を使うか、今の `l2_ops` なら**正規化を外す**必要あり。
* **タイマーの同時起動対策**

  * `oneshot`でも重いジョブが重なる可能性あり。`flock`ロックを `ExecStartPre` で入れるか、`RefuseManualStart` 等の運用ルールを明記。

---

# 中程度（整備で良くなる）

* **ログ**：`print` ベース → `logging`（構造化JSON）へ。
* **要件の満たし方**：`genre_hint` は **IPTCコード（例：`medtop:04000000`）**で保存できているが、**`hint` テーブルに部分インデックス**（`WHERE key='genre_hint'`）があると高速。
* **バージョン固定**：`requirements.txt` は素の名前のみ。**最小限のピン止め**推奨（下に例）。
* **README** のコマンドブロックが二重になっている箇所がある（体裁修正）。

---

## “まず動く”ための最小修正パッチ（提案）

> ここを当てるだけで **RSS取り込み → 埋め込み → MCP検索（fallback含む）** まで通る想定です。
> 以降は Entity / Event / NewsAPI / HN を段階的に拡張。

### 1) `scripts/ingest_rss.py`（UTC変換とURL正規化の修復）

```diff
@@
-def to_utc(dt_like) -> datetime:
-    if not dt_like:
-        return datetime.now(timezone.utc)
-    if isinstance(dt_like, datetime):
-        if dt_like.tzinfo is None:
-            return dt_like.replace(tzinfo=timezone.utc)
-        return dt_like.astimezone(timezone.utc)
-    # string
-    try:
-        d = parsedate_to_datetime(str(dt_like))
-        if d.tzinfo is None:
-            d = d.replace(tzinfo=timezone.utc)
-        return d.astimezone(timezone.utc)
-    except Exception:
-        return dat
+def to_utc(dt_like) -> datetime:
+    if not dt_like:
+        return datetime.now(timezone.utc)
+    if isinstance(dt_like, datetime):
+        return (dt_like.replace(tzinfo=timezone.utc)
+                if dt_like.tzinfo is None else dt_like.astimezone(timezone.utc))
+    try:
+        d = parsedate_to_datetime(str(dt_like))
+        d = d.replace(tzinfo=timezone.utc) if d.tzinfo is None else d.astimezone(timezone.utc)
+        return d
+    except Exception:
+        return datetime.now(timezone.utc)
@@
-def canonicalize_url(url: str) -> str:
-    try:
-...
+def canonicalize_url(url: str) -> str:
+    """UTM等のトラッキングやフラグメントを削除して正規化"""
+    try:
+        u = urlparse.urlsplit(url)
+        q = urlparse.parse_qsl(u.query, keep_blank_values=False)
+        q = [(k, v) for (k, v) in q if k.lower() not in
+             {"utm_source","utm_medium","utm_campaign","utm_term","utm_content","gclid","fbclid"}]
+        new_q = urlparse.urlencode(q)
+        return urlparse.urlunsplit((u.scheme, u.netloc, u.path, new_q, ""))  # drop fragment
+    except Exception:
+        return url
```

### 2) `mcp_news/server.py`（検索の最小安定化）

```diff
@@
-from mcp.server.fastmcp import FastMCP
+from mcp.server.fastmcp import FastMCP
+from sentence_transformers import SentenceTransformer
@@
 mcp = FastMCP("NewsHub")
+EMBED_SPACE = "bge-m3"  # embed_chunks.py の --space と一致させる
+_MODEL = None
+if os.getenv("ENABLE_SERVER_EMBEDDING", "0").lower() in ("1","true","yes"):
+    _MODEL = SentenceTransformer(os.getenv("EMBEDDING_MODEL", "intfloat/multilingual-e5-base"))
@@
 def _row_to_bundle(row: psycopg.rows.Row) -> Bundle:
@@
 @mcp.tool()
 def semantic_search(q: str, top_k: int = 50, since: Optional[str] = None) -> List[Bundle]:
-    ...
+    since_dt = None
+    if since:
+        try:
+            since_dt = datetime.fromisoformat(since)
+            if since_dt.tzinfo is None:
+                since_dt = since_dt.replace(tzinfo=timezone.utc)
+            since_dt = since_dt.astimezone(timezone.utc)
+        except Exception:
+            since_dt = None
+    # Vector search (cos距離 or L2はDB定義に合わせる)
+    if _MODEL is not None:
+        try:
+            q_emb = _MODEL.encode([q], normalize_embeddings=True)[0].tolist()
+            cond = "AND d.published_at >= %s" if since_dt else ""
+            params = [EMBED_SPACE] + ([since_dt] if since_dt else []) + [q_emb, top_k]
+            sql = f"""
+              SELECT d.doc_id, d.title_raw, d.published_at,
+                     (SELECT val FROM hint WHERE doc_id=d.doc_id AND key='genre_hint') AS genre_hint,
+                     d.url_canon
+              FROM chunk_vec v
+              JOIN chunk c ON c.chunk_id = v.chunk_id
+              JOIN doc   d ON d.doc_id   = c.doc_id
+              WHERE v.embedding_space=%s {cond}
+              ORDER BY v.emb <-> %s
+              LIMIT %s
+            """
+            with connect() as conn:
+                rows = conn.execute(sql, tuple(params)).fetchall()
+                if rows:
+                    return [_row_to_bundle(r) for r in rows]
+        except Exception:
+            pass
+    # Fallback: recency
+    with connect() as conn:
+        cond = "WHERE d.published_at >= %s" if since_dt else ""
+        params = [since_dt, top_k] if since_dt else [top_k]
+        rows = conn.execute(f"""
+          SELECT d.doc_id, d.title_raw, d.published_at,
+                 (SELECT val FROM hint WHERE doc_id=d.doc_id AND key='genre_hint') AS genre_hint,
+                 d.url_canon
+          FROM doc d {cond}
+          ORDER BY d.published_at DESC
+          LIMIT %s
+        """, tuple(params)).fetchall()
+        return [_row_to_bundle(r) for r in rows]
@@
-if __name__ == "__main__":
-    # stdio transport
-    mcp.run()
+if __name__ == "__main__":
+    mcp.run_stdio()
```

### 3) HNSWインデックス（`db/schema_v2.sql`）

```diff
--- a/db/schema_v2.sql
+++ b/db/schema_v2.sql
@@
--- CREATE INDEX IF NOT EXISTS idx_chunk_vec_hnsw ON chunk_vec USING hnsw (emb vector_l2_ops) WHERE embedding_space='bge-m3';
+-- Cos類似を使うなら vector_cosine_ops、L2なら normalize=False で揃えること
+CREATE INDEX IF NOT EXISTS idx_chunk_vec_hnsw_bge_m3
+  ON chunk_vec USING hnsw (emb vector_l2_ops)
+  WHERE embedding_space='bge-m3';
+CREATE INDEX IF NOT EXISTS idx_hint_genre ON hint (doc_id) WHERE key='genre_hint';
+CREATE INDEX IF NOT EXISTS idx_entity_ext ON entity (ext_id);
```

### 4) systemd の“かち合い”防止（例：`deploy/embed.service`）

```diff
 [Service]
 Type=oneshot
+RuntimeDirectory=mcp-news
+ExecStartPre=/usr/bin/flock -n /run/mcp-news/embed.lock -c 'true'
 Environment=DATABASE_URL=postgresql://localhost/newshub
 ...
```

### 5) 依存バージョンの軽いピン止め（`requirements.txt`）

```diff
-mcp
-psycopg[binary]
-pgvector
-feedparser
-pydantic
-sentence-transformers
-httpx
+mcp>=1.0.0
+psycopg[binary]>=3.2.1
+pgvector>=0.2.5
+feedparser>=6.0.11
+pydantic>=2.7.0
+sentence-transformers>=2.7.0
+httpx>=0.27.0
```

---

# 仕様との整合（必須要件の満たし方）

* **ニュースのタイトル** → `doc.title_raw` を `doc_head/semantic_search` が返却。
* **時間** → `doc.published_at`（UTC保存、MCP側でISO8601出力）。
* **ジャンル（推測）** → `hint(key='genre_hint', val=IPTCコード)` を**必ず一緒に返す**実装になっている（ここはOK）。
  ※ サンプルフィードではすべて `medtop:04000000` になっているので、NewsAPIやRSSのカテゴリを**初期ヒント**に流用する実装を後日追記（現段階でも欠損は許容という前提ならMVPクリア）。

---

# レポート類のレビュー（`docs/`）

* **FINAL\_REPORT.md / RESUME\_MANUAL.md**：十分に実用的。次の作業順も妥当。
* **README\_UBUNTU.md**：一部のコードブロックが重複して見える箇所があり、体裁を1回整えるとさらに親切。

---

# 次の一手（Day-1の“完了条件”に向けて）

1. 上記パッチを当てて **RSS→Embed→MCP** を通す。
2. `db/chunk_vec` に HNSW索引を作成（space一致）。
3. `scripts/eval_metrics.sql` で取り込み件数と未埋め込み件数を確認。
4. `mcp_news.server` の `semantic_search` を一度 **MODEL無効**（`ENABLE_SERVER_EMBEDDING=0`）で起動し、**recency fallback が正しく返る**こともテスト。
5. 落ち着いたら **NewsAPI/HN の ingest を修復**（現在プレースホルダあり）。

> ここまでで「**タイトル／時間／ジャンル**を返すAIネイティブMCP」が最低限動作します。

---

# リスクとフォロー

* **プレースホルダ残り**：生成途中の断片が複数。**まずビルド通る最小差分で修復**し、その後にEntity/Eventへ。
* **距離関数の不整合**：cos/L2の混在は検索品質を大きく下げます。DBのオペレータと埋め込み正規化の整合を**最初に固定**。
* **APIキー管理**：`EnvironmentFile` 未設定のサービス（embed等）にも統一導入を。

---

必要なら、この“最小修正パッチ”を**丸ごと置換版ファイル**として出します。まずは **RSSパスを通す**→**MCP検索のfallback含む応答確認**まで一気に進めましょう。
